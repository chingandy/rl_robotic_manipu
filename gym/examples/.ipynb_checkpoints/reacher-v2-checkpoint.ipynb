{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reacher-v2 Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "vec_body_1:  [0.1  0.   0.01]\n",
      "vec_target:  [ 0.1  -0.1   0.01]\n",
      "Inner product:  0.010100000000000001\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Reacher-v2\")\n",
    "state = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating offscreen glfw\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAf1ElEQVR4nO2df8wlVXnHv18W0YWlsCt2uwsrLLiVXUuqdKU0NQZrW4U/itrEYBNLWpNtE2zapDWl9Y+a/khso21i0pqulRRtKyVRw6ahP5BqjCYqqMgCK7roIrtddgUKriwWWJ7+MXPvO3fuzNxzZs6Zec7M88nefWfOOfPMc+c953ue58y981JEYBiGUeS0oR0wDEMfJgyGYSxhwmAYxhImDIZhLGHCYBjGEiYMhmEsEU0YSL6Z5IMkD5K8MdZ5DMMID2N8joHkOgDfAvBLAA4DuAvAO0TkgeAnMwwjOLEihisAHBSR74jIswBuAXBtpHMZhhGY0yPZPR/AI4X9wwB+tq7xhg0bZNOmTZFcMYYmRFRqNrrbOHbs2GMi8jKXtrGEYSUk9wDYAwAbN27Ee97znqFcaQ3JoV0YnGIHLXfWujrXdmYjjI0ZH/jABx5eKqwhVipxBMC2wv4FedkcEdkrIrtFZPeGDRsqjZBU/TIWxbHpmjS1MxvuNurqmtq1IVbEcBeAHSS3IxOE6wD8msuBNuDCEvN6zmYlkgvbs7ridlM7Xxu+9sdko+319iWKMIjI8yTfDeA/AawDcJOI3B/jXEMzZSErd9BiJ6yrc223qq6rH1O14Uq0NQYRuR3A7V3tTHngpYCWDj8VGyEE1wVVn3wMnScZ/ZN6Dh/CRpt1gCHfZxWqhKGIiUIYyPiLr2MaeFoHbywBqGOw25VjYcoCFjvkTSG0T82GK8kIw5QHoGbKnRAY7m6FFhu+9vuy4YPaVMIIg6US/dsoo8WGD8lEDFqZciRjqUR6NlxJUhimPBi1oaXDT8VGCMF1wVIJIyhawuaxpjqhfFxFkhGDJqYevaS2ANeHDV/7fdnwIXlhmPrAHJoUwu8x2bBUwkgSLeGxpRLdUgkThglA2u3K1AdvLAGoI/lUQgNTTWdih7wphPap2XBldMIw1UE6FFo6/FRshBBcF0YnDMYiMYVyqBV4X/tjstH1ertiwtCRKUcolkqkZ8OVUS8+kvbcx9gUr0HT9WhqZzb6XTR1YdTCYPRP6gMvhI0Qg7fP91mFCcMEiB0tjWngaR28MaODKmyNIQBTTSlIW2NIzYYrkxKGqQ7gmJQ7IaD7+wJ92PC135cNHyyVGDmx0ghLJSyVMBqYchRiqUR6NlyZbMQQetacKqnNmqnbCBHpuDBZYTDikPrAC2EjtTSlChOGCRAqOqqLlsY08LQO3pjRQRW2xoBprxN0YXbdUvu+QMo2ul5vVyxiMIKiZXYca0QTysdVmDCMnFhpxFgHntbBa6lEgkw1FSmHr3a7Ur8NVyxiqKDtzDlFUps1U7cRItJxwSKGCRBLvFJdgEvZRtfr7YoJQwCmGjVYKpGeDVcslViBpRLNpBB+j8lGEqkEyUMATgA4BeB5EdlNchOAfwVwEYBDAN4uIv/b5Tya+Pp/f3FoF9TTNEPV1bU5JkadzzGn5AXs+rmfSSZa8iFEKvEGEXmssH8jgDtF5P0kb8z3/zDAeQbnwOe/ghNff6hVaGaMD5LY//3P4rJfeUMSKYYPMdYYrgVwVb59M4DPYQTC8MV/ug0vHHsKZ73oJUO7Yiji5BMnceiu/bjotZepEYAQQtFVGATAf5EUAH8vInsBbBaRo3n9owA2Vx1Icg+APQCwcePGjm7E5at3fgGnclF4xYXbIfICAM7+LW1nUVu+V9ietVkL64ptiscu22xsN9ti1f5yuzW7pfJSUdvVE6ndWSyQhd1so9yHFzu1LB1XrBfIkr1ZG2k4T2ZDCnZl8Rxzu4vlJHHw4e/i6fu/hwdPPYdXXnm56jsePnQVhteJyBGSPw7gDpLfLFaKiOSisUQuInsB4OUvf7nq2Py0wi9DJOscs0EoxcFe/gXM9jkb2FyqY2GfFWXzfXKxbcV5WNhesFN1vtneol7Us6pzFWe2clVNWxbrC2XF9syvd6HhWhsREJwPVs4HrgDzclm7XoXyud184AiYlRUdYPEcsuCxiMx9FinWLaMlkvChkzCIyJH853GSnwZwBYBjJLeIyFGSWwAc7+ylMkjikaP/szy9LTXM/5u1K0YSzidDxcjCwkCvrHa1v+rcTXTsf6sPl87nyKxkdorCPI89ZG2/XtDydgWB37Zl65JvWgRg0FSC5FkAThORE/n2LwP4UwD7AFwP4P35z9sc7bV1pV+y8AAigh8883Rvpyz/ahO5Wp3QGkaes/4sZNHWsoexBSDEHQ8XukQMmwF8Oh/QpwP4FxH5D5J3AbiV5LsAPAzg7b6G2967bbLhWrfSt9L+iWefaW3LSI+zz1ifbVTrQlY15duVIvIdAD9dUf44gDe2tduFEGKwWnjyssIv4PFnTjjZNtLmpevPnm+XE8JVfU9DiuGDfSTaF84WGheLr//z9wzjjwIW7gzUbLet02Jj3wf/YaFdtmApS2Wz41zvJjTVxbhb4Yp9JNqTtfsBU8jy/WmKuNqkgVpsVFTW9gDX1FfL+6zChKENqSyUFiDtQS1dbSzTPT0dWgDqsFTCFy78qG6SoHC0IfbqeZ/59yobS+3n//XrR1+3Ky1i8ISwJKJIyulB95m3QjASiJZcsIjBl1IYnQKx/G2zeKZhAa6tj3OILJ2siSpi+9HlertiwhCZ1ETEh+mmErRUwlgk6xBU+6m8vkktDQgSfotkEcOIUwkTBm9o6wwNaBm8oW34EGLwDrNmsoYJgyeppgak3a7samOtMC937AqaBaAOW2Nog0enWD40TWGpYsprDGv/9+uHrTEoprpbTJPybNU0E8/2XdtpsrH0vkvtu9ivahfThgsmDJ4w6xFJyUKMNGLKqQSzipXtuvoY2oYPJgwtCCUKsQZs3QAOzVCDN4QfbW2UjhrMj7Y2XDFh8CalWCE+Wjp83zNvrVQkEC25YMLQBob5zvsY0TJ4Q9uorvc7t9ZoqQoTBk/m1zexwCFmitJ3p4458JzTCI+BplkA6rDblZ7MLnyM5ceY6wExmPk7xPcWfOyH+n5G+b1LzRqD5u+JuGIRQxsSG8B9omV2tFTCUoneSVEWLJUIm0qUS1MQOh9MGLzpRxZiDeLQPlZtN9VpnTXbiEO5L6TwXlwxYWiDpRJztHT43mdesnKOSCFacsGEwZfq/mDkaBm8oW0sViz8cD631mipCrsr4QkH+NJ1rFQgBJqeshTTxgwC+d/JROVdiaHumrjY8MEihjboHae9k3IU0MaGrDXwth/CD0slFGO6UI+GwRvDxlId6peaxpBKmDB4ojmsb4K025VdbTSRgtD5YMLQhoHFocsgDu1H1XZTndZZ01scuLzWlMJ7ccWEwRdaKlGk3AmbBGG279pOk415eVZZm0q0sV/VLqYNF0wYPElVFLqkDKsikL5nx5jRiFO04ImWSMIHE4ZW6JGHNgM51Hld90MP3iZfYtsAir/99N6LKyYM3lguMcNndk1h0LjakKyBt/0QfoQQXBdMGIxOpB4BuNrwIbVoqYqVwkDyJpLHSd5XKNtE8g6S385/bszLSfJDJA+SvJfk5V7eJEKKAYNryuHzajpX1bZPu9izZhsbC+VYDBpSEDofXCKGfwTw5lLZjQDuFJEdAO7M9wHgagA78tceAB8O4qUiSGY9Qqk6+A7ikOcq15Xblbdd6qra+doPaaNQiKo1hth++Npv+/tfKQwi8nkAT5SKrwVwc759M4C3FMo/JhlfAnAuyS3eXiUBtWrDYKyabfucHUPb8CFmRON6Lh8bVbRdY9gsIkfz7UcBbM63zwfwSKHd4bzMGJiYaUSbUNznOG2phK9caBaAOjovPkr21S3vr2+R3EPybpJ3//CHP+zqRq+kEinETCVCzX5aBk0bcSgXp/BeXGkrDMdmKUL+83hefgTAtkK7C/KyJURkr4jsFpHdGzZsmJeHUMO24aGL/QhjLFnGLACh04hQfoSIllxoKwz7AFyfb18P4LZC+a8z40oATxVSjqiEFoMQs2xXEUqBUKmDa7uhbPgQM9VxPZePjSpWPqiF5CcAXAXgPJKHAfwJgPcDuJXkuwA8DODtefPbAVwD4CCAkwB+w8ubJGBj2BBCoGLPNCGZPTik6a9DN/3F5qKNYttVdUM9qKXwRlBMKmcp21ge1LJSGETkHTVVb6xoKwBu8PYiMcYx14dh1vGaOmCVcGj8E/GuNpqI7UeT+IR8L/bJR19MFWoJFcFoCbEb62prxpFKmDB4wtLPFJmFvV1eZXtV233XxbaxhGMn0CwAdZgwGK0Yc3Tg6n+5NIX34ooJQxsCqXLqtBGHqo6qZdD4DagasYjsR4hoyQV7fLw34xKFtjNK06LXrL5uQazYplxXZaN8vqa6WDaW4Py/hbZ9+OFjf+XdlRosYjBasWpGqosQfEJ2jZFEE1oiGksljEFp01FXHadFANoOqLGkEiYMLRhXMtGN0B28S11MG0t1tTVhBu/QQmfC4MvIVYEM95CW8n7s6CD2zNsWzQJQhwmD0YqiQJTFomm/qlPXCc4qm66+hLSx6GBptwc/fO2vEvI6TBiMTvjMVnXiUGdv1f6QqUQTlkpMkJFnEgt0TSVipRyDpxJc+FHfrqOPoW34YMJgtCLGTNg21+9z4DWhRQBCCIUJg9GaIcVB68wb248Q0ZILJgxtCBSujYE+Uoeu54uyxtDi3CkJnX0k2nCGJHDoceCpkwCA/Scfx/5jlU/uq/3+f9NzAdrWrarfeeFWPPDoYezafjEuvfBiANl76fSglgrKNkf9oBbDmPPkSeDhx+e7l+FM3Pe44BMHvzWgUw584wDwyhfjU984hJ0P3Yv3/kL21w7Kg6ZuYPvgaqOpXZu60O/FhKEtU8wmCqIw4zU/sRX/fuJpZxOV3dOh0y60qI1G8pbkQpsTP3oMG7ZuwrPPP4cD//skvvmdh3DpxZcAcB+8PoQYvDEExgdbY0iYEGF5uV1Tne95nHA4fH4KgZOIVLU59fyp7E8EvfCC20knjrqIoZhDlffLdXXH+dioq2s6l6v/Ifxosu9j08fP2nbnrAeffGah/uMH7sOTTyxHEqo4/Vk8c+w5YN1p2HnmJuy8ZEc3QZuArqgRhhCDN/TA61sc2thwtVPVxvu6XvhSyDlngt/LheCcM3HZky/DT8l5jdeir7q68p0XnY8Hjj4CnDqFX/3F8p9hNapQIwyArgdzlNu5+B7DDxcfq/ysGthV+ab3NTl3PeTcC+bHX3fh1bXXosqvujqflKaNjZ2XXrrkp1GPujWGtjlv7E5WOqg3P3zs17XzOXfb802OkV8LNcIw1Czj44crsf3QVGeMEzXCAMQfNKFt1B3Ttx8mDkZoVAlDGS0CsNBuaaO6XSg/2kRLvm1djyu3q3tNhTG/U3XCoCX07juNCP0+Xe2sep8WKUwTNcJQnG3KM095u6mdrw0f+1lhvf99+eFqo1hf9V5cruMqX4xxokYYqtCSSriiJZVw9cPHZpUdl9eoGfHbUyEMQwpAm1SiqT9oSSX6qJsyY78SKoQBiD9rhhh4rmiJdEJGBy7tjPGgRhiA4QZNiFlSiwCsGvAubavOZeIwLVR9JBrIOl2fH332sZ97WBtH9uVHqI9PV32HYrZfttF8TabKeK+BmoghrVSiuUNoiWhWtauLENqmHJNi5NdhpTCQvInkcZL3FcreR/IIyXvy1zWFuj8ieZDkgyTf5OOMlkHTWOdgrw8/YtrwsWmME5eI4R8BVH1X9W9E5NX563YAILkLwHUAXpUf83ck17V1TsugWTyooSqGEEWOlrrUdX2lipR+jpGVwiAinwfwhKO9awHcIiL/JyLfBXAQwBU+DvUeATgOvIVjamuGTXUsOuiZEV+aLmsM7yZ5b55qbMzLzgfwSKHN4bxsCZJ7SN5N8u6nn346sTWGZjQKwKoB72LHRGKNsV+JtnclPgzgz5Bdnz8D8EEAv+ljQET2AtgLANu2bZO8TOWDWhYHhFQuPMXyw/d9trVRbDuj6W5FaP7zt38b608/HT84dQrbb7gBu171qkqfQgt827qsD4xXHlpFDCJyTEROicgLAD6CtXThCIBthaYX5GU+tmv3taQSTaSWSrRNOULzY+vXY8f27TgDwEtOi3uzLHbkU2c/ikBFotVvgOSWwu5bAczuWOwDcB3JF5PcDmAHgK+42LRUQo+NIdYcvv+jH2H/Qw9h3StegYt37oxyjtC4XIrYYhDrd7UylSD5CQBXATiP5GEAfwLgKpKvRhZLHQLwW7kj95O8FcADAJ4HcIOInHJ1phwed31Qaigbi8et9l3zewldF4pdv/M7eOjAAfzC294W1G4sUksifEVipTCIyDsqij/a0P4vAPyFlxf1tgYbNCt9W3GuUH7U1YUa5E3+r7IZkkt27sQliUQKU0DNJx9naAmbp7rG0Oe6QopI4f8xo0YYRBJ5UMuKuxJ9+BHKhov9Yn319QhD+Rwxz9UZAaDZvwCoEYYqdM6w9fPFkBFN7GtVbhf6lRrpeeyHCmEYUgAslRj+joShDxXCACQ2a4o0/rHr1AWgrt2qtpNC5v+NEjXCAKQyaKqXn7QM3thpyipf2pJeyqHJl/CoEoYyWmZNV7QM3tjXarYf8pUiaXrthhphmHWOckcp7lfVubbramOtzSyKlNrPMoT0w/d99mVj6ow8k9AjDEAa4Tccblf240d3GyGikVAkF2UMff7IqBKGMsMKQHW7JrQO3hjXKvQrRVL12wV1wqB11lwrb44gNQ3emDamztivjBphSGHWLFQAQO0tSy2Dt7frMUVGfilUPT5eROeDWkpeQkCAi30jlh++77MvG4agevl5HKiJGGaoTyWWNuL6Ecp+aBtTR+b/jRM1wpBMKiGYpxJtbKQmACYUNYz8WqgRBkBPh2+2URNJKB28sQU3FCIp3uUYrzioEoYyGmdNoL47aB28Ma5VmgM5HOl57Ic6YdA6a66V17oQxY9Q9kPbmDwjvzZq7krMOmHfK/Au9kueVpb7+Kjlzouv/XK7kKQkQvP7EQn57Iu6iKGI2tmxNpqwVGISqUTubmpu+6BCGIYUAEslLJXwheS4VQFKhAFIY9acl9ce3Y8fWmwY470eaoQB0NPhm224pREpvJcQghuSGClKrLRlvJKQoUoYymicNfOC2mcxhPZDS7RUrtM6YPtAgKwPpOOyN2qEYdYxyp2kuF9V59quq42FNiveR0g/fN9nXzamTXMfGANqblcCWcfT+GfdFo7D7FuVyzPqWP5EXVs/upCU6Agw6nABiiKGKrSkEosH5W0rmlsqMf40okiqfrugThj6FgDXgeeKpsEb08aUEczmhfFeHzXCkMKsmZdmYWRDOK1l8PZzPaYHAUDGvc6geo0B0PGglsXBgaxn1Aw0bR9bjmVj6sj8v3GiJmKYkUQq0aMfoeyHtjF5ZC2hGCNqhCGpVGIFWgavpRLxGLcsKE8ltNziWzwOlU+B7cMPu12pA1naGB8rIwaS20h+luQDJO8n+bt5+SaSd5D8dv5zY15Okh8ieZDkvSQvb+ucllmzZNHpXKH80BItletCv5IjRZ89cEklngfw+yKyC8CVAG4guQvAjQDuFJEdAO7M9wHgagA78tceAB/2cUj7GkO26GRrDNNG8v/He31WphIichTA0Xz7BMkDAM4HcC2Aq/JmNwP4HIA/zMs/Jlmv+hLJc0luye00nQdAAg9qkeoOse+D/9D09owxIXk/Ga8u+K0xkLwIwGsAfBnA5sJgfxTA5nz7fACPFA47nJc1CkMVQ+bfZRuFvezvShR46fqz/d6YkTbzfrKsDG0iLtfork+chYHkBgCfBPB7IvKD0gATkl7vgOQeZKkGzjnnnKItlQtw8/bz/zLOPmO961vujfBLg/oodzZWlPV5fu/jW4pBmzWnNjgJA8kXIROFfxaRT+XFx2YpAsktAI7n5UcAbCscfkFetoCI7AWwFwC2bt0qIQZv7AgjKwRAAUj82PqzZgflozFrW7a8cCMjb1dsI/nxDDGkC340Nul8jgYCjNAqEwuDv6rje6iDFLdmO65PZpq1SySVaCMSK4WB2cj4KIADIvLXhap9AK4H8P78522F8neTvAXAzwJ4atX6woy+04M2tyuB7Hv427ZsBbg2lOfHc00cimVrwpBvl8pmx1S2zf8k3nL5Wl3x+ELNGqyQndK1aRzvq25RNs1ySzuyXCcVZXl5bRuRhe1yO5nvylJZsf38dzwrq2o7r8v+E5EwQq4Ul4jh5wG8E8B+kvfkZX+MTBBuJfkuAA8DeHtedzuAawAcBHASwG+0dU7LGgOwVkeeVpgt5lNNvvLAQvRQqJW8Np9pBAA565jM7WM+ExXLpRBJZMcVyzE//2I9CvtrbSRvWicHsrjbutvL0sZybTklWxCLUnl5f62NlNovDt6mdrOCRT+kYnutDRe2UegTxAsju4PjclfiC6jvI2+saC8AbvB1ZDYwQ9xpCG3jlVdejkPr9uPk/d/DwYe/6/vWjBFz8rkfYd3mc/Azb3zd0K4ExT756Gjjotdehv1HH8PTT5wcbKXY0AVJvOy1l2Ln668Y2pXgqBKGMlpSiVndZb/yBnzzS19byi3rjqtPTfTUtbVnZIxRFACFwqD1duVs/9Irs094l/0o7tdtt63TasMYL/btygB+TNXG1BAZ4Xc+alAVMWheYxijDd9oaZUfXRnTwEodVcIA+N1pqGrna8PX/phsdL3exnixVCKAH1O1MTVcUomxpBWqIoYUwu8x2dCWSszsG8OjJmKoIoVZM7YNrdFSrJehA3XCMKaBN/TgjWnDGDdqUolZJ0xtAS5lG12vd2hMiPSgLmIoomV2tFSin1TC0IMKYRjrwBt68Ma0YYwbFcIA2MBL0cYUmUp0pGaNAVjObTXe4huTjbq6tn6EIIVBMwXURAxVpDBrppzqdPEx1svQgZqIYTYTzTrH0B8X1mLD135fNqbIlIRLjTAAaYTfY7KhLZWY0sDTjqUSym1MKZUw9KBOGMY08IYevDFtGONGjTDYwEvPxhSJFS1pi5xsjWHCNurq2voRAi0DY+qoEgZguRMCur8vkLKNrtfbGC9qhCH2zJbCDJ6ajakxJUFUIwyAng4/FRvaUokpDTztqFl8rKLYUcqdpqluTDbq6kLY6OJjjJehB3XCMKaBN/TgjWnDGDdqUonYIW8KoX1qNqbIVMRSjTAAy50Q0P19gT5s+Nrvy4YxblSkEmPN4S2VMFJFTcRgqUR6NqbIVMRSjTAAejr8VGyEENzQTGXgaUdFKlGHlrB5rKlOFx9jvQwdqIkYZjPRrHOksADXhw1f+33ZmCpTEa+VEQPJbSQ/S/IBkveT/N28/H0kj5C8J39dUzjmj0geJPkgyTe5OpPCDD4mGyGikdDEjEYsonHHJWJ4HsDvi8jXSJ4N4Ksk78jr/kZEPlBsTHIXgOsAvArAVgCfIfmTInLK17ny7JVaDh/CRl1dCBtdfDT0EuL3szJiEJGjIvK1fPsEgAMAzm845FoAt4jI/4nIdwEcBHCFq0MpzpoxbZTRYsPQSdPv0wevxUeSFwF4DYAv50XvJnkvyZtIbszLzgfwSOGww6gQEpJ7SN5N8u6TJ0/awEvQxhQZOpVZ9QqFszCQ3ADgkwB+T0R+AODDAC4B8GoARwF80OfEIrJXRHaLyO4zzzxzVlasbzq2tp3ZsDWGFAaedpzuSpB8ETJR+GcR+RQAiMixQv1HAPxbvnsEwLbC4RfkZU6I2EeO+7LR9XobOgnx+3G5K0EAHwVwQET+ulC+pdDsrQDuy7f3AbiO5ItJbgewA8BXfJyKMbOlMIOnZmOqDB219BHVuEQMPw/gnQD2k7wnL/tjAO8g+WoAAuAQgN/KL9r9JG8F8ACyOxo3SMc7Ek115XZNdWZD/ycfZ+cwhoUafgkkvw/gaQCPDe2LA+chDT+BdHw1P8NT5euFIvIyl4NVCAMAkLxbRHYP7ccqUvETSMdX8zM8XX1V/V0JwzCGwYTBMIwlNAnD3qEdcCQVP4F0fDU/w9PJVzVrDIZh6EFTxGAYhhIGFwaSb86/nn2Q5I1D+1OG5CGS+/Ovlt+dl20ieQfJb+c/N66yE8Gvm0geJ3lfoazSL2Z8KL/G95K8XIGvwb+2H8DPukcMqLquDX6Gu6YDf0JrHYCHAFwM4AwA3wCwa+hPjpV8PATgvFLZXwG4Md++EcBfDuDX6wFcDuC+VX4BuAbAvwMggCsBfFmBr+8D8AcVbXfl/eDFALbn/WNdT35uAXB5vn02gG/l/qi6rg1+BrumQ0cMVwA4KCLfEZFnAdyC7Gvb2rkWwM359s0A3tK3AyLyeQBPlIrr/LoWwMck40sAzi19pD0qNb7W0elr+12Q+kcMqLquDX7W4X1NhxYGp69oD4wA+C+SXyW5Jy/bLCJH8+1HAWwexrUl6vzSep1bf20/Nlx8xIDa61ryEwh0TYcWhhR4nYhcDuBqADeQfH2xUrJYTd2tHa1+Fej0tf2YcPkRA3M0XdcKP4Nd06GFodNXtPtARI7kP48D+DSyEOzYLGTMfx4fzsMF6vxSd51F5JiInBKRFwB8BGuh7aC+suIRA1B4Xav8DHlNhxaGuwDsILmd5BnInhW5b2Cf5pA8i9lzLkHyLAC/jOzr5fsAXJ83ux7AbcN4uESdX/sA/Hq+in4lgKcKofEgMOLX9jv4VPmIASi7rnV+Br2mfayirlhhvQbZqupDAN47tD8l3y5Gtpr7DQD3z/wD8FIAdwL4NoDPANg0gG+fQBYuPocsZ3xXnV/IVs3/Nr/G+wHsVuDrx3Nf7s077pZC+/fmvj4I4Ooe/XwdsjThXgD35K9rtF3XBj+DXVP75KNhGEsMnUoYhqEQEwbDMJYwYTAMYwkTBsMwljBhMAxjCRMGwzCWMGEwDGMJEwbDMJb4f+fpAcVfu2bRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = env.render(mode='rgb_array', width=256, height=256)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(11,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.05, 0], [0.05, 0], [0, -0.05], [0, 0.05]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space\n",
    "# [random.choice(env.action_space) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  1\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.09969872 -0.0077566   0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.007206184907153642\n",
      "Creating window glfw\n",
      "Step:  2\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.09965184 -0.0083373   0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.00717821832702315\n",
      "Step:  3\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.09956659 -0.00930018  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0071312705440097065\n",
      "Step:  4\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.0994327 -0.0106366  0.01     ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.007064917963636531\n",
      "Step:  5\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.09923603 -0.01233739  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.006978462674820388\n",
      "Step:  6\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.09895884 -0.01439261  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.006870965665707995\n",
      "Step:  7\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.09858019 -0.01679128  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.006741282615108935\n",
      "Step:  8\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.09807614 -0.01952103  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0065881023285701374\n",
      "Step:  9\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.0974202  -0.02256777  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.00640998792627559\n",
      "Step:  10\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.09658364 -0.02591526  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.006205420894158009\n",
      "Step:  11\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.09553589 -0.02954478  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.005972848082571361\n",
      "Step:  12\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.094245  -0.0334347  0.01     ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.005710731681131764\n",
      "Step:  13\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.09267813 -0.03756014  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.005417602116361771\n",
      "Step:  14\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.09080205 -0.04189256  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.00509211371308826\n",
      "Step:  15\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.08858377 -0.04639952  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.004733102833831685\n",
      "Step:  16\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.08599113 -0.05104434  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.004339648065652144\n",
      "Step:  17\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.08299354 -0.05578595  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0039111318644465065\n",
      "Step:  18\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.07956269 -0.06057869  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.003447302896367897\n",
      "Step:  19\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.07567334 -0.06537236  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0029483381392705447\n",
      "Step:  20\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.07130416 -0.07011217  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0024149036288814863\n",
      "Step:  21\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.06643857 -0.07473899  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0018482125603966873\n",
      "Step:  22\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.06106559 -0.0791896   0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0012500792926235756\n",
      "Step:  23\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.05518075 -0.08339715  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0006229676554132624\n",
      "Step:  24\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.0487869  -0.08729169  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  2.996816084977856e-05\n",
      "Step:  25\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.04189502 -0.09080092  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0007048519450054988\n",
      "Step:  26\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.03452499 -0.09385108  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0013970648959929202\n",
      "Step:  27\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.02670625 -0.09636792  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.002101238010283181\n",
      "Step:  28\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.01847831 -0.09827793  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0028112592407963893\n",
      "Step:  29\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.00989122 -0.09950962  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.00352029713121267\n",
      "Step:  30\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.00100575 -0.09999494  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0042208424526734645\n",
      "Step:  31\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.00810649 -0.09967088  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.004904769123002285\n",
      "Step:  32\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.01736329 -0.09848104  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.005563415369394274\n",
      "Step:  33\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.02667219 -0.09637735  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.006187685703695172\n",
      "Step:  34\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.03593117 -0.09332176  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0067681738169134776\n",
      "Step:  35\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.04502961 -0.08928793  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.007295305971090313\n",
      "Step:  36\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.05384952 -0.08426286  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.00775950387951507\n",
      "Step:  37\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.06226703 -0.07824843  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.008151365430904436\n",
      "Step:  38\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.07015426 -0.07126275  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.008461860942947926\n",
      "Step:  39\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.07738136 -0.06334133  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.008682541941907408\n",
      "Step:  40\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.0838189  -0.05453799  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.008805758776861355\n",
      "Step:  41\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.08934039 -0.04492544  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.008824882711305293\n",
      "Step:  42\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.0938251  -0.03459553  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.008734527514801036\n",
      "Step:  43\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.09716094 -0.02365909  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.008530765028328611\n",
      "Step:  44\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.09924743 -0.01224533  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.008211328724836908\n",
      "Step:  45\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.09999875 -0.00050076  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.007775798957076629\n",
      "Step:  46\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.09934665  0.01141238  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.007225763403042866\n",
      "Step:  47\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.09724332  0.02331816  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0065649462082115395\n",
      "Step:  48\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.09366393  0.03502953  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.005799299503179685\n",
      "Step:  49\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.08860896  0.0463514   0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0049370513611995985\n",
      "Step:  50\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.0821061   0.05708404  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.003988704863207365\n",
      "Step:  51\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.07421167  0.06702706  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.002966983762975522\n",
      "Step:  52\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.06501148  0.0759836   0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0018867212897070087\n",
      "Step:  53\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.05462106  0.08376479  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0007646898798203559\n",
      "Step:  54\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.04318521  0.09019444  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.00038062892420923593\n",
      "Step:  55\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.03087683  0.09511373  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0015293335587534998\n",
      "Step:  56\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.01789491  0.09838583  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0026604479167506036\n",
      "Step:  57\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.00446179  0.09990041  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0037523187980236434\n",
      "Step:  58\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [0.00918033 0.09957772 0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.004783059045292471\n",
      "Step:  59\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [0.0227737  0.09737227 0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.005731028231331197\n",
      "Step:  60\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [0.03604992 0.09327595 0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.006575340995488215\n",
      "Step:  61\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [0.04873555 0.08732037 0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.007296391505531046\n",
      "Step:  62\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [0.06055812 0.07957835 0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.007876381109303991\n",
      "Step:  63\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [0.07125259 0.07016458 0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.008299835104785167\n",
      "Step:  64\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [0.08056801 0.05923509 0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.008554093758173852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  65\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [0.08827422 0.04698577 0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.008629762293070118\n",
      "Step:  66\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [0.09416845 0.0336497  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.008521104606601305\n",
      "Step:  67\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [0.09808164 0.0194934  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.008226365976564143\n",
      "Step:  68\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [0.09988416 0.0048119  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.007748011030166194\n",
      "Step:  69\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.09949096 -0.01007712  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.007092864757483396\n",
      "Step:  70\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.09686571 -0.02484016  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.006272146362272564\n",
      "Step:  71\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.09202395 -0.03913557  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.005301388222409801\n",
      "Step:  72\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.08503499 -0.05262177  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.004200235136713922\n",
      "Step:  73\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.07602248 -0.06496601  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.002992122300740462\n",
      "Step:  74\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.06516354 -0.07585323  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0017038340003240838\n",
      "Step:  75\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.05268638 -0.08499498  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0003649487413014245\n",
      "Step:  76\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.03886638 -0.09213796  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0009928196636299071\n",
      "Step:  77\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.02402077 -0.09707215  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0023363717759128278\n",
      "Step:  78\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [ 0.00850175 -0.09963795  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0036320461279571443\n",
      "Step:  79\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.00731154 -0.09973235  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.004846496615359888\n",
      "Step:  80\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.02302226 -0.0973138   0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.005947600734511647\n",
      "Step:  81\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.03822599 -0.09240549  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.006905373448740895\n",
      "Step:  82\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.05252147 -0.08509698  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.007692859874785331\n",
      "Step:  83\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.06552178 -0.07554401  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.008286979162179478\n",
      "Step:  84\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.0768655  -0.06396636  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.008669291967152546\n",
      "Step:  85\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.08622762 -0.05064383  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.008826664851076067\n",
      "Step:  86\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.0933298  -0.03591027  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.008751806784328041\n",
      "Step:  87\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.09794972 -0.0201458   0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.008443655701613595\n",
      "Step:  88\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.09992901 -0.00376743  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.00790759669360603\n",
      "Step:  89\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.09917976  0.01278183  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.007155497858320596\n",
      "Step:  90\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.09568904  0.02904494  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.006205554967391207\n",
      "Step:  91\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.08952136  0.04456373  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.005081941790190032\n",
      "Step:  92\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.08081898  0.05889221  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0038142689978091803\n",
      "Step:  93\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.06979974  0.07161003  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0024368608515100546\n",
      "Step:  94\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.05675268  0.08233549  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  0.0009878651609672273\n",
      "Step:  95\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.04203123  0.09073795  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0004917819399232902\n",
      "Step:  96\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.02604429  0.09654893  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.001959509227894607\n",
      "Step:  97\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [-0.00924528  0.09957171  0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.003372349494498069\n",
      "Step:  98\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [0.00788047 0.09968901 0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.004688228266991581\n",
      "Step:  99\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [0.02482975 0.09686838 0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0058672628235611176\n",
      "Step:  100\n",
      "Action:  [-0.05, 0]\n",
      "##################################################\n",
      "vec_body_1:  [0.0410964  0.09116516 0.01      ]\n",
      "vec_target:  [-0.07654873 -0.04198044  0.01      ]\n",
      "Inner product:  -0.0068730303075588035\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "step = 0\n",
    "for _ in range(100):\n",
    "    step += 1\n",
    "    print(\"Step: \", step)\n",
    "#     action = random.choice(env.action_space)\n",
    "    action = env.action_space[0]\n",
    "    print(\"Action: \", action)\n",
    "    env.step(action)\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating offscreen glfw\n",
      "In def step....... True\n",
      "In def step....... True\n",
      "In def step....... True\n",
      "In def step....... True\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "for _ in range(10):\n",
    "    data = env.render(mode='rgb_array', width=256, height=256)\n",
    "    images.append(data)\n",
    "#     action = env.action_space.sample()\n",
    "#     actions = [[0.1, 0], [0,0.1]]\n",
    "#     action = random.choice(actions)\n",
    "    action = random.choice(env.action_space)\n",
    "#     print(\"Action: \", action)\n",
    "    env.step(action)\n",
    "env.close()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3600x3600 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (50,50))\n",
    "for i in range(len(images)):\n",
    "    ax = fig.add_subplot(1, 10, i + 1)\n",
    "    ax.imshow(images[i])\n",
    "    print(images[i].shape)\n",
    "plt.show()\n",
    " \n",
    "# plt.imshow(data, interpolation='nearest')\n",
    "\n",
    "# w=10\n",
    "# h=10\n",
    "# fig=plt.figure(figsize=(8, 8))\n",
    "# columns = 5\n",
    "# rows = 2\n",
    "# for i in range(1, columns*rows +1):\n",
    "#     img = np.random.randint(10, size=(h,w))\n",
    "#     fig.add_subplot(rows, columns, i)\n",
    "#     plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densely-connected NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0703 11:02:19.252130 4513461696 deprecation_wrapper.py:119] From /Users/chingandywu/master-thesis/code/.venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0703 11:02:19.272954 4513461696 deprecation_wrapper.py:119] From /Users/chingandywu/master-thesis/code/.venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0703 11:02:19.277594 4513461696 deprecation_wrapper.py:119] From /Users/chingandywu/master-thesis/code/.venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0703 11:02:19.371757 4513461696 deprecation_wrapper.py:119] From /Users/chingandywu/master-thesis/code/.venv/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0703 11:02:19.379557 4513461696 deprecation_wrapper.py:119] From /Users/chingandywu/master-thesis/code/.venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0703 11:02:19.478890 4513461696 deprecation_wrapper.py:119] From /Users/chingandywu/master-thesis/code/.venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                192       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                192       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-trained model doesn't exist.\n",
      "Creating window glfw\n",
      "episode: 0   score: -25.86932558732607  q_value: [0.9997298]   memory length: 100\n",
      "episode: 1   score: -36.823674479194786  q_value: [0.9997298]   memory length: 200\n",
      "episode: 2   score: -31.312982375386575  q_value: [0.9997298]   memory length: 300\n",
      "episode: 3   score: -14.430007506003822  q_value: [0.9997298]   memory length: 400\n",
      "episode: 4   score: -25.457681007735804  q_value: [0.9997298]   memory length: 500\n",
      "episode: 5   score: -34.03548296357584  q_value: [0.9997298]   memory length: 600\n",
      "episode: 6   score: -28.844050204037924  q_value: [0.9997298]   memory length: 700\n",
      "episode: 7   score: -26.355784316277994  q_value: [0.9997298]   memory length: 800\n",
      "episode: 8   score: -20.085547720344167  q_value: [0.9997298]   memory length: 900\n",
      "episode: 9   score: -32.352453995804225  q_value: [0.9997298]   memory length: 1000\n",
      "episode: 10   score: -33.392781576262145  q_value: [0.98248142]   memory length: 1100\n",
      "episode: 11   score: -37.689845902906335  q_value: [0.73899363]   memory length: 1200\n",
      "episode: 12   score: -35.58960076368598  q_value: [0.60534071]   memory length: 1300\n",
      "episode: 13   score: -38.33951808322531  q_value: [0.43830349]   memory length: 1400\n",
      "episode: 14   score: -30.78085514633394  q_value: [0.24359159]   memory length: 1500\n",
      "episode: 15   score: -33.22027305039436  q_value: [0.04179902]   memory length: 1600\n",
      "episode: 16   score: -14.364634093468073  q_value: [-0.16324102]   memory length: 1700\n",
      "episode: 17   score: -25.155986730694682  q_value: [-0.36604082]   memory length: 1800\n",
      "episode: 18   score: -16.146146104043964  q_value: [-0.54075153]   memory length: 1900\n",
      "episode: 19   score: -6.187756344137266  q_value: [-0.71362027]   memory length: 2000\n",
      "episode: 20   score: -20.01790841703296  q_value: [-0.86319761]   memory length: 2100\n",
      "episode: 21   score: -24.984676087356068  q_value: [-1.01074988]   memory length: 2200\n",
      "episode: 22   score: -29.17247687668243  q_value: [-1.15039243]   memory length: 2300\n",
      "episode: 23   score: -30.779045071480784  q_value: [-1.29026946]   memory length: 2400\n",
      "episode: 24   score: -18.273750648746947  q_value: [-1.41841198]   memory length: 2500\n",
      "episode: 25   score: -28.51761629489831  q_value: [-1.54926481]   memory length: 2600\n",
      "episode: 26   score: -26.23520146022143  q_value: [-1.6726321]   memory length: 2700\n",
      "episode: 27   score: -37.063148053625945  q_value: [-1.80526929]   memory length: 2800\n",
      "episode: 28   score: -18.08125311085332  q_value: [-1.93488376]   memory length: 2900\n",
      "episode: 29   score: -14.500837552834732  q_value: [-2.0575911]   memory length: 3000\n",
      "episode: 30   score: -28.343676945724052  q_value: [-2.17436452]   memory length: 3100\n",
      "episode: 31   score: -28.024609708001563  q_value: [-2.29416859]   memory length: 3200\n",
      "episode: 32   score: -28.64414093371857  q_value: [-2.35777311]   memory length: 3300\n",
      "episode: 33   score: -17.664992124107926  q_value: [-2.45686335]   memory length: 3400\n",
      "episode: 34   score: -27.148043775343673  q_value: [-2.52318582]   memory length: 3500\n",
      "episode: 35   score: -35.73621752827904  q_value: [-2.59901081]   memory length: 3600\n",
      "episode: 36   score: -19.037270592407822  q_value: [-2.64413917]   memory length: 3700\n",
      "episode: 37   score: -37.73865165109726  q_value: [-2.65116648]   memory length: 3800\n",
      "episode: 38   score: -36.26132823652429  q_value: [-2.65651769]   memory length: 3900\n",
      "episode: 39   score: -20.406261646912036  q_value: [-2.56647268]   memory length: 4000\n",
      "episode: 40   score: -11.041037782369528  q_value: [-2.52340226]   memory length: 4100\n",
      "episode: 41   score: -21.586581763006407  q_value: [-2.41839095]   memory length: 4200\n",
      "episode: 42   score: -28.798153488981026  q_value: [-2.27271935]   memory length: 4300\n",
      "episode: 43   score: -35.54148205472145  q_value: [-2.06207737]   memory length: 4400\n",
      "episode: 44   score: -16.525341341970456  q_value: [-1.79749966]   memory length: 4500\n",
      "episode: 45   score: -22.103171501592673  q_value: [-1.53364155]   memory length: 4600\n",
      "episode: 46   score: -33.66813506657022  q_value: [-1.27165033]   memory length: 4700\n",
      "episode: 47   score: -30.916054519879342  q_value: [-1.00432809]   memory length: 4800\n",
      "episode: 48   score: -20.070073133764986  q_value: [-0.70000754]   memory length: 4900\n",
      "episode: 49   score: -25.917554130388577  q_value: [-0.39160782]   memory length: 5000\n",
      "episode: 50   score: -23.725189667003626  q_value: [-0.05255261]   memory length: 5100\n",
      "episode: 51   score: -15.94311230201878  q_value: [0.26292517]   memory length: 5200\n",
      "episode: 52   score: -20.943148373686807  q_value: [0.52611057]   memory length: 5300\n",
      "episode: 53   score: -15.758285896282048  q_value: [0.85677972]   memory length: 5400\n",
      "episode: 54   score: -8.852935618939487  q_value: [1.1161192]   memory length: 5500\n",
      "episode: 55   score: -17.62306735446735  q_value: [1.35242276]   memory length: 5600\n",
      "episode: 56   score: -27.308227466108523  q_value: [1.56100184]   memory length: 5700\n",
      "episode: 57   score: -15.058449366360062  q_value: [1.72751256]   memory length: 5800\n",
      "episode: 58   score: -7.397182964223251  q_value: [1.90064859]   memory length: 5900\n",
      "episode: 59   score: -34.59017103989484  q_value: [1.9321926]   memory length: 6000\n",
      "episode: 60   score: -17.329188420846627  q_value: [2.00933704]   memory length: 6100\n",
      "episode: 61   score: -35.56107232670189  q_value: [2.05349707]   memory length: 6200\n",
      "episode: 62   score: -25.335747031385903  q_value: [2.10364667]   memory length: 6300\n",
      "episode: 63   score: -17.710065016047103  q_value: [2.11367034]   memory length: 6400\n",
      "episode: 64   score: -23.081567990439158  q_value: [2.06699621]   memory length: 6500\n",
      "episode: 65   score: -11.487724023455293  q_value: [2.09454133]   memory length: 6600\n",
      "episode: 66   score: -22.365675707762048  q_value: [2.00279325]   memory length: 6700\n",
      "episode: 67   score: -24.397759388914622  q_value: [1.92579199]   memory length: 6800\n",
      "episode: 68   score: -26.45495352517552  q_value: [1.84637691]   memory length: 6900\n",
      "episode: 69   score: -37.19445688637367  q_value: [1.73515071]   memory length: 7000\n",
      "episode: 70   score: -9.213296672346656  q_value: [1.63597712]   memory length: 7100\n",
      "episode: 71   score: -15.006299327135173  q_value: [1.51393907]   memory length: 7200\n",
      "episode: 72   score: -19.882643937965916  q_value: [1.39481831]   memory length: 7300\n",
      "episode: 73   score: -34.61923613730998  q_value: [1.24973213]   memory length: 7400\n",
      "episode: 74   score: -33.54007394402239  q_value: [1.11308392]   memory length: 7500\n",
      "episode: 75   score: -17.222085635843616  q_value: [0.95909308]   memory length: 7600\n",
      "episode: 76   score: -35.19598568127092  q_value: [0.84972367]   memory length: 7700\n",
      "episode: 77   score: -27.437297928134118  q_value: [0.707791]   memory length: 7800\n",
      "episode: 78   score: -20.414776617871194  q_value: [0.60366607]   memory length: 7900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 79   score: -35.70713297950104  q_value: [0.50492205]   memory length: 8000\n",
      "episode: 80   score: -9.783940754495793  q_value: [0.36532146]   memory length: 8100\n",
      "episode: 81   score: -34.52760158385352  q_value: [0.20692421]   memory length: 8200\n",
      "episode: 82   score: -13.883601915110072  q_value: [0.06753497]   memory length: 8300\n",
      "episode: 83   score: -11.734129309455216  q_value: [-0.07461735]   memory length: 8400\n",
      "episode: 84   score: -23.18922711832245  q_value: [-0.20055466]   memory length: 8500\n",
      "episode: 85   score: -16.96210573371665  q_value: [-0.32427388]   memory length: 8600\n",
      "episode: 86   score: -27.986504527558594  q_value: [-0.47611272]   memory length: 8700\n",
      "episode: 87   score: -9.64423191546522  q_value: [-0.58269612]   memory length: 8800\n",
      "episode: 88   score: -26.96735319794081  q_value: [-0.65700873]   memory length: 8900\n",
      "episode: 89   score: -10.951261897427125  q_value: [-0.74077006]   memory length: 9000\n",
      "episode: 90   score: -40.52462838591315  q_value: [-0.85532418]   memory length: 9100\n",
      "episode: 91   score: -15.345128401807896  q_value: [-0.9763707]   memory length: 9200\n",
      "episode: 92   score: -31.55834161161696  q_value: [-1.08190179]   memory length: 9300\n",
      "episode: 93   score: -2.9290907286569836  q_value: [-1.16370115]   memory length: 9400\n",
      "episode: 94   score: -33.59150705038  q_value: [-1.2199584]   memory length: 9500\n",
      "episode: 95   score: -19.839522714750146  q_value: [-1.2895023]   memory length: 9600\n",
      "episode: 96   score: -36.77544947106654  q_value: [-1.36511925]   memory length: 9700\n",
      "episode: 97   score: -22.18012274069357  q_value: [-1.45948621]   memory length: 9800\n",
      "episode: 98   score: -12.073420198941903  q_value: [-1.53416005]   memory length: 9900\n",
      "episode: 99   score: -13.667453264613828  q_value: [-1.57872739]   memory length: 10000\n",
      "episode: 100   score: -8.514987360323058  q_value: [-1.68728748]   memory length: 10100\n",
      "episode: 101   score: -8.565727768794059  q_value: [-1.73830652]   memory length: 10200\n",
      "episode: 102   score: -36.007486219518846  q_value: [-1.78236707]   memory length: 10300\n",
      "episode: 103   score: -20.9966932267618  q_value: [-1.84257652]   memory length: 10400\n",
      "episode: 104   score: -37.681491745311284  q_value: [-1.85921906]   memory length: 10500\n",
      "episode: 105   score: -35.22858482360559  q_value: [-1.85531535]   memory length: 10600\n",
      "episode: 106   score: -34.888885679091736  q_value: [-1.83146571]   memory length: 10700\n",
      "episode: 107   score: -31.804908259272473  q_value: [-1.77228867]   memory length: 10800\n",
      "episode: 108   score: -38.49705516844695  q_value: [-1.75983934]   memory length: 10900\n",
      "episode: 109   score: -30.842471851298725  q_value: [-1.75666011]   memory length: 11000\n",
      "episode: 110   score: -13.42058571261346  q_value: [-1.74030759]   memory length: 11100\n",
      "episode: 111   score: -30.40124346030093  q_value: [-1.69872511]   memory length: 11200\n",
      "episode: 112   score: -38.464010477947426  q_value: [-1.65078564]   memory length: 11300\n",
      "episode: 113   score: -12.06073697855405  q_value: [-1.54987219]   memory length: 11400\n",
      "episode: 114   score: -18.891961892225275  q_value: [-1.46299019]   memory length: 11500\n",
      "episode: 115   score: -2.8521259167086517  q_value: [-1.35337107]   memory length: 11600\n",
      "episode: 116   score: -24.706290512150442  q_value: [-1.29718873]   memory length: 11700\n",
      "episode: 117   score: -20.592874744418374  q_value: [-1.09989793]   memory length: 11800\n",
      "episode: 118   score: -7.166427547326217  q_value: [-0.89170364]   memory length: 11900\n",
      "episode: 119   score: -9.09649935709585  q_value: [-0.69072924]   memory length: 12000\n",
      "episode: 120   score: -38.933734662103745  q_value: [-0.42883839]   memory length: 12100\n",
      "episode: 121   score: -6.222388735659955  q_value: [-0.21788933]   memory length: 12200\n",
      "episode: 122   score: -33.929047874492944  q_value: [-0.03288669]   memory length: 12300\n",
      "episode: 123   score: -12.702073350313958  q_value: [0.15922725]   memory length: 12400\n",
      "episode: 124   score: -21.782017448311738  q_value: [0.370631]   memory length: 12500\n",
      "episode: 125   score: -4.693843284514541  q_value: [0.60422883]   memory length: 12600\n",
      "episode: 126   score: -21.903682080828773  q_value: [0.87630168]   memory length: 12700\n",
      "episode: 127   score: -22.098621604697247  q_value: [1.05043277]   memory length: 12800\n",
      "episode: 128   score: -22.047624644850764  q_value: [1.28633336]   memory length: 12900\n",
      "episode: 129   score: -29.991075441206668  q_value: [1.50320039]   memory length: 13000\n",
      "episode: 130   score: -21.320508167447418  q_value: [1.75030129]   memory length: 13100\n",
      "episode: 131   score: -13.104667097172804  q_value: [1.93235504]   memory length: 13200\n",
      "episode: 132   score: -11.960344352471694  q_value: [2.08063712]   memory length: 13300\n",
      "episode: 133   score: -25.135401487294576  q_value: [2.26930817]   memory length: 13400\n",
      "episode: 134   score: -21.8577008020199  q_value: [2.41584119]   memory length: 13500\n",
      "episode: 135   score: -18.558865693417708  q_value: [2.52888329]   memory length: 13600\n",
      "episode: 136   score: -32.33611724757795  q_value: [2.6053064]   memory length: 13700\n",
      "episode: 137   score: -8.625959948019958  q_value: [2.70329306]   memory length: 13800\n",
      "episode: 138   score: -28.386539954203748  q_value: [2.83437644]   memory length: 13900\n",
      "episode: 139   score: -26.705757277825562  q_value: [2.89835963]   memory length: 14000\n",
      "episode: 140   score: -30.32146220645315  q_value: [2.92647315]   memory length: 14100\n",
      "episode: 141   score: -39.292190994550396  q_value: [2.94293969]   memory length: 14200\n",
      "episode: 142   score: -13.553551889397895  q_value: [2.89287015]   memory length: 14300\n",
      "episode: 143   score: -5.104607721837775  q_value: [2.8702307]   memory length: 14400\n",
      "episode: 144   score: -24.696055717410268  q_value: [2.7663407]   memory length: 14500\n",
      "episode: 145   score: -26.218055346642092  q_value: [2.68712293]   memory length: 14600\n",
      "episode: 146   score: -16.02755388882641  q_value: [2.59789714]   memory length: 14700\n",
      "episode: 147   score: -35.663234283816635  q_value: [2.46463489]   memory length: 14800\n",
      "episode: 148   score: -26.134705136626277  q_value: [2.36790047]   memory length: 14900\n",
      "episode: 149   score: -26.244606117265416  q_value: [2.24331991]   memory length: 15000\n",
      "episode: 150   score: -18.746488719054803  q_value: [2.08938546]   memory length: 15100\n",
      "episode: 151   score: -24.370942339372803  q_value: [2.00537557]   memory length: 15200\n",
      "episode: 152   score: -24.281352716012943  q_value: [1.88005471]   memory length: 15300\n",
      "episode: 153   score: -4.089471503591838  q_value: [1.78520453]   memory length: 15400\n",
      "episode: 154   score: -25.72166344775395  q_value: [1.64480691]   memory length: 15500\n",
      "episode: 155   score: -16.790499714774583  q_value: [1.5165873]   memory length: 15600\n",
      "episode: 156   score: -32.59443946462993  q_value: [1.37431229]   memory length: 15700\n",
      "episode: 157   score: -31.3262619666179  q_value: [1.23770044]   memory length: 15800\n",
      "episode: 158   score: -24.066010823953867  q_value: [1.09453394]   memory length: 15900\n",
      "episode: 159   score: -31.205171731502162  q_value: [0.95742311]   memory length: 16000\n",
      "episode: 160   score: -28.055996510717417  q_value: [0.77203712]   memory length: 16100\n",
      "episode: 161   score: -36.04140476304868  q_value: [0.59811386]   memory length: 16200\n",
      "episode: 162   score: -7.134128778654035  q_value: [0.52234312]   memory length: 16300\n",
      "episode: 163   score: -38.9815294362408  q_value: [0.39521079]   memory length: 16400\n",
      "episode: 164   score: -23.470607499794298  q_value: [0.29625559]   memory length: 16500\n",
      "episode: 165   score: -28.037891494150514  q_value: [0.17906559]   memory length: 16600\n",
      "episode: 166   score: -25.09508698536008  q_value: [0.07447551]   memory length: 16700\n",
      "episode: 167   score: -12.827003505444686  q_value: [0.000411]   memory length: 16800\n",
      "episode: 168   score: -10.732934252439252  q_value: [-0.108771]   memory length: 16900\n",
      "episode: 169   score: -13.349051280518903  q_value: [-0.19869445]   memory length: 17000\n",
      "episode: 170   score: -29.47529009451719  q_value: [-0.27623509]   memory length: 17100\n",
      "episode: 171   score: -11.936291893586302  q_value: [-0.3473834]   memory length: 17200\n",
      "episode: 172   score: -19.86548781459411  q_value: [-0.48778007]   memory length: 17300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 173   score: -19.39180336429283  q_value: [-0.58190168]   memory length: 17400\n",
      "episode: 174   score: -35.62982127348452  q_value: [-0.68631484]   memory length: 17500\n",
      "episode: 175   score: -27.02438239879492  q_value: [-0.780523]   memory length: 17600\n",
      "episode: 176   score: -11.828276571257652  q_value: [-0.88893991]   memory length: 17700\n",
      "episode: 177   score: -18.534280337792218  q_value: [-1.00178151]   memory length: 17800\n",
      "episode: 178   score: -18.85438512745956  q_value: [-1.11614865]   memory length: 17900\n",
      "episode: 179   score: -15.30288810942187  q_value: [-1.19431146]   memory length: 18000\n",
      "episode: 180   score: -16.869562694736338  q_value: [-1.25554752]   memory length: 18100\n",
      "episode: 181   score: -15.175167762167414  q_value: [-1.41965762]   memory length: 18200\n",
      "episode: 182   score: -22.733567344099143  q_value: [-1.55252481]   memory length: 18300\n",
      "episode: 183   score: -27.73353166200314  q_value: [-1.62261305]   memory length: 18400\n",
      "episode: 184   score: -13.239800669244884  q_value: [-1.73397436]   memory length: 18500\n",
      "episode: 185   score: -25.14930617480693  q_value: [-1.81105077]   memory length: 18600\n",
      "episode: 186   score: -28.888883418191664  q_value: [-1.91475509]   memory length: 18700\n",
      "episode: 187   score: -19.230160525459215  q_value: [-1.9902301]   memory length: 18800\n",
      "episode: 188   score: -23.934823364661224  q_value: [-2.10390228]   memory length: 18900\n",
      "episode: 189   score: -22.854777641923192  q_value: [-2.17745292]   memory length: 19000\n",
      "episode: 190   score: -19.513909324997197  q_value: [-2.24536923]   memory length: 19100\n",
      "episode: 191   score: -15.33479739040266  q_value: [-2.35892149]   memory length: 19200\n",
      "episode: 192   score: -36.37292324489148  q_value: [-2.42553401]   memory length: 19300\n",
      "episode: 193   score: -15.983959666934275  q_value: [-2.50893508]   memory length: 19400\n",
      "episode: 194   score: -29.52573889928392  q_value: [-2.53729571]   memory length: 19500\n",
      "episode: 195   score: -17.07584206942013  q_value: [-2.6118111]   memory length: 19600\n",
      "episode: 196   score: -30.642397583167615  q_value: [-2.66120477]   memory length: 19700\n",
      "episode: 197   score: -31.340870302204394  q_value: [-2.72529382]   memory length: 19800\n",
      "episode: 198   score: -38.87242098742485  q_value: [-2.79382539]   memory length: 19900\n",
      "episode: 199   score: -12.95034579900378  q_value: [-2.85359245]   memory length: 20000\n",
      "episode: 200   score: -32.98643593786104  q_value: [-2.90866594]   memory length: 20100\n",
      "episode: 201   score: -10.567978395011277  q_value: [-3.00069094]   memory length: 20200\n",
      "episode: 202   score: -34.15740488380547  q_value: [-3.07093958]   memory length: 20300\n",
      "episode: 203   score: -14.9379472165128  q_value: [-3.14799251]   memory length: 20400\n",
      "episode: 204   score: -12.784430813608436  q_value: [-3.21229336]   memory length: 20500\n",
      "episode: 205   score: -11.871926472345255  q_value: [-3.23353908]   memory length: 20600\n",
      "episode: 206   score: -24.3498429744793  q_value: [-3.22484723]   memory length: 20700\n",
      "episode: 207   score: -12.338975754103302  q_value: [-3.2799293]   memory length: 20800\n",
      "episode: 208   score: -10.892463179522304  q_value: [-3.29066331]   memory length: 20900\n",
      "episode: 209   score: -21.937734971518985  q_value: [-3.33514455]   memory length: 21000\n",
      "episode: 210   score: -10.91198345992182  q_value: [-3.37258483]   memory length: 21100\n",
      "episode: 211   score: -34.48752384041576  q_value: [-3.42466418]   memory length: 21200\n",
      "episode: 212   score: -33.127792189551634  q_value: [-3.45728746]   memory length: 21300\n",
      "episode: 213   score: -26.665105900685088  q_value: [-3.48408833]   memory length: 21400\n",
      "episode: 214   score: -28.207175076275927  q_value: [-3.49057475]   memory length: 21500\n",
      "episode: 215   score: -32.093919526306586  q_value: [-3.53164728]   memory length: 21600\n",
      "episode: 216   score: -10.971749503393138  q_value: [-3.51247158]   memory length: 21700\n",
      "episode: 217   score: -9.92752115627383  q_value: [-3.5664114]   memory length: 21800\n",
      "episode: 218   score: -35.45700278692127  q_value: [-3.59065747]   memory length: 21900\n",
      "episode: 219   score: -33.93618526612421  q_value: [-3.52637494]   memory length: 22000\n",
      "episode: 220   score: -19.233387641572012  q_value: [-3.55090745]   memory length: 22100\n",
      "episode: 221   score: -16.795914798564297  q_value: [-3.53237369]   memory length: 22200\n",
      "episode: 222   score: -22.56048933026679  q_value: [-3.53721573]   memory length: 22300\n",
      "episode: 223   score: -6.250036731758585  q_value: [-3.50190006]   memory length: 22400\n",
      "episode: 224   score: -22.20904649452024  q_value: [-3.5225738]   memory length: 22500\n",
      "episode: 225   score: -16.67169868158121  q_value: [-3.53896707]   memory length: 22600\n",
      "episode: 226   score: -15.037926779339232  q_value: [-3.53714121]   memory length: 22700\n",
      "episode: 227   score: -28.10886088405702  q_value: [-3.50096909]   memory length: 22800\n",
      "episode: 228   score: -13.433227298699292  q_value: [-3.48368426]   memory length: 22900\n",
      "episode: 229   score: -22.66931955845259  q_value: [-3.47554922]   memory length: 23000\n",
      "episode: 230   score: -4.6689573464980025  q_value: [-3.44782697]   memory length: 23100\n",
      "episode: 231   score: -14.111141764666263  q_value: [-3.42262057]   memory length: 23200\n",
      "episode: 232   score: -10.200612289996846  q_value: [-3.45740918]   memory length: 23300\n",
      "episode: 233   score: -12.206062085551595  q_value: [-3.47657978]   memory length: 23400\n",
      "episode: 234   score: -22.434096267453207  q_value: [-3.38316175]   memory length: 23500\n",
      "episode: 235   score: -16.66512690404316  q_value: [-3.31204806]   memory length: 23600\n",
      "episode: 236   score: -7.450822206092515  q_value: [-3.31025013]   memory length: 23700\n",
      "episode: 237   score: -22.66714194173559  q_value: [-3.26780812]   memory length: 23800\n",
      "episode: 238   score: -12.247476676046094  q_value: [-3.27793418]   memory length: 23900\n",
      "episode: 239   score: -19.610914309461826  q_value: [-3.21445963]   memory length: 24000\n",
      "episode: 240   score: -11.497172163591461  q_value: [-3.13082856]   memory length: 24100\n",
      "episode: 241   score: -36.55320134575424  q_value: [-3.06971978]   memory length: 24200\n",
      "episode: 242   score: -18.092277153347652  q_value: [-2.97130173]   memory length: 24300\n",
      "episode: 243   score: -7.903221312448414  q_value: [-2.98061381]   memory length: 24400\n",
      "episode: 244   score: -18.939624043509156  q_value: [-2.97263382]   memory length: 24500\n",
      "episode: 245   score: -19.473250448800023  q_value: [-2.8864623]   memory length: 24600\n",
      "episode: 246   score: -22.047140481530356  q_value: [-2.92621725]   memory length: 24700\n",
      "episode: 247   score: -10.067800725903032  q_value: [-2.7808963]   memory length: 24800\n",
      "episode: 248   score: -27.6434192482952  q_value: [-2.75545135]   memory length: 24900\n",
      "episode: 249   score: -28.829252496980075  q_value: [-2.68183351]   memory length: 25000\n",
      "episode: 250   score: -13.112570716993071  q_value: [-2.66258137]   memory length: 25100\n",
      "episode: 251   score: -33.7233909970182  q_value: [-2.55482132]   memory length: 25200\n",
      "episode: 252   score: -16.244718491869786  q_value: [-2.47950884]   memory length: 25300\n",
      "episode: 253   score: -26.772641627211765  q_value: [-2.44147279]   memory length: 25400\n",
      "episode: 254   score: -24.982031404650947  q_value: [-2.41478506]   memory length: 25500\n",
      "episode: 255   score: -37.02147595657477  q_value: [-2.34601763]   memory length: 25600\n",
      "episode: 256   score: -24.57064645221509  q_value: [-2.31889234]   memory length: 25700\n",
      "episode: 257   score: -34.13451339156935  q_value: [-2.26752072]   memory length: 25800\n",
      "episode: 258   score: -25.3645840763529  q_value: [-2.26569055]   memory length: 25900\n",
      "episode: 259   score: -32.19093844119034  q_value: [-2.21256254]   memory length: 26000\n",
      "episode: 260   score: -10.115212348651895  q_value: [-2.18489219]   memory length: 26100\n",
      "episode: 261   score: -15.863302948367954  q_value: [-2.17493604]   memory length: 26200\n",
      "episode: 262   score: -30.699474011958934  q_value: [-2.14305395]   memory length: 26300\n",
      "episode: 263   score: -16.481896240406304  q_value: [-2.14474185]   memory length: 26400\n",
      "episode: 264   score: -28.862948259565982  q_value: [-2.15594415]   memory length: 26500\n",
      "episode: 265   score: -21.040861453843096  q_value: [-2.18970458]   memory length: 26600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 266   score: -10.141194656234466  q_value: [-2.20842392]   memory length: 26700\n",
      "episode: 267   score: -23.102591609453498  q_value: [-2.22525878]   memory length: 26800\n",
      "episode: 268   score: -38.23139987669317  q_value: [-2.23387898]   memory length: 26900\n",
      "episode: 269   score: -23.43751682798192  q_value: [-2.26520426]   memory length: 27000\n",
      "episode: 270   score: -18.187494748128486  q_value: [-2.26513649]   memory length: 27100\n",
      "episode: 271   score: -12.94042272995857  q_value: [-2.23468946]   memory length: 27200\n",
      "episode: 272   score: -35.4566825522454  q_value: [-2.28268496]   memory length: 27300\n",
      "episode: 273   score: -16.750140018454722  q_value: [-2.32509834]   memory length: 27400\n",
      "episode: 274   score: -28.7013123236339  q_value: [-2.39639563]   memory length: 27500\n",
      "episode: 275   score: -11.498752177151385  q_value: [-2.44845401]   memory length: 27600\n",
      "episode: 276   score: -11.428066909471156  q_value: [-2.50201386]   memory length: 27700\n",
      "episode: 277   score: -21.455843806708998  q_value: [-2.56808656]   memory length: 27800\n",
      "episode: 278   score: -33.65315137409342  q_value: [-2.58096354]   memory length: 27900\n",
      "episode: 279   score: -25.519422152509932  q_value: [-2.5672442]   memory length: 28000\n",
      "episode: 280   score: -38.27027487915398  q_value: [-2.6111431]   memory length: 28100\n",
      "episode: 281   score: -20.486335111098384  q_value: [-2.65224051]   memory length: 28200\n",
      "episode: 282   score: -30.412583510644954  q_value: [-2.65418876]   memory length: 28300\n",
      "episode: 283   score: -11.638593946668577  q_value: [-2.70666216]   memory length: 28400\n",
      "episode: 284   score: -28.646364877936136  q_value: [-2.73794361]   memory length: 28500\n",
      "episode: 285   score: -35.61931510271272  q_value: [-2.74052234]   memory length: 28600\n",
      "episode: 286   score: -26.679725769613334  q_value: [-2.75996409]   memory length: 28700\n",
      "episode: 287   score: -15.825727064535013  q_value: [-2.77110609]   memory length: 28800\n",
      "episode: 288   score: -17.133969867156882  q_value: [-2.785619]   memory length: 28900\n",
      "episode: 289   score: -28.778065699894395  q_value: [-2.79819769]   memory length: 29000\n",
      "episode: 290   score: -22.944666486680475  q_value: [-2.809187]   memory length: 29100\n",
      "episode: 291   score: -16.698318321391167  q_value: [-2.87489771]   memory length: 29200\n",
      "episode: 292   score: -11.375819833579087  q_value: [-2.85594359]   memory length: 29300\n",
      "episode: 293   score: -18.230599630964907  q_value: [-2.84000344]   memory length: 29400\n",
      "episode: 294   score: -9.785544696704411  q_value: [-2.80325704]   memory length: 29500\n",
      "episode: 295   score: -25.02273888358712  q_value: [-2.80460915]   memory length: 29600\n",
      "episode: 296   score: -22.982635365057263  q_value: [-2.78417347]   memory length: 29700\n",
      "episode: 297   score: -9.973758150137458  q_value: [-2.83411178]   memory length: 29800\n",
      "episode: 298   score: -4.958799549843276  q_value: [-2.80735611]   memory length: 29900\n",
      "episode: 299   score: -36.13080961075361  q_value: [-2.78870954]   memory length: 30000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.models import Sequential, load_model\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "EPISODES = 300#Maximum number of episodes\n",
    "INITIAL_EPSILON = 1.0 # Initial value of epsilon in epsilon-greedy\n",
    "FINAL_EPSILON = 0.1\n",
    "EXPLORATION_STEPS = 1e6\n",
    "# random.seed(2)  # fix the random seed\n",
    "#DQN Agent for the reacher-v2\n",
    "#Q function approximation with NN, experience replay, and target network\n",
    "class DQNAgent:\n",
    "    #Constructor for the agent (invoked when DQN is first called in main)\n",
    "    def __init__(self, state_size, action_space):\n",
    "        self.check_solve = False\n",
    "        self.render = True # visualize the training process \n",
    "        self.action_space = action_space\n",
    "        #Get size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = len(action_space)\n",
    "        \n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "        #Set hyper parameters for the DQN. Do not adjust those labeled as Fixed.\n",
    "        self.discount_factor = 0.98\n",
    "        self.learning_rate = 0.001 #6e-6  # 0.005\n",
    "        self.epsilon = INITIAL_EPSILON\n",
    "        self.epsilon_interval = (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORATION_STEPS\n",
    "        self.batch_size = 32 #Fixed\n",
    "        self.memory_size = 500000  # 1000\n",
    "        self.train_start = 1000 #Fixed\n",
    "        self.target_update_frequency = 1\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "        #Number of test states for Q value plots\n",
    "        self.test_state_no =10000 # 10000\n",
    "\n",
    "        #Create memory buffer using deque\n",
    "        self.memory = deque(maxlen=self.memory_size)\n",
    "\n",
    "        #Create main network and target network (using build_model defined below)\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "\n",
    "        #Initialize target network\n",
    "        self.update_target_model()\n",
    "\n",
    "    #Approximate Q function using Neural Network\n",
    "    #State is the input and the Q Values are the output.\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "        #Edit the Neural Network model here\n",
    "        #Tip: Consult https://keras.io/getting-started/sequential-model-guide/\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(16, input_dim=self.state_size, activation='relu',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(16, activation='relu',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "#         model.add(Dense(32, activation='relu',\n",
    "#                         kernel_initializer='he_uniform'))\n",
    "#         model.add(Dense(16, activation='relu',\n",
    "#                         kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.action_size, activation='linear',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.summary()\n",
    "        opt = Adam(lr=self.learning_rate, decay=1e-6)\n",
    "#         loss = tf.losses.huber_loss\n",
    "#         model.compile(loss='logcosh', optimizer=opt)\n",
    "        model.compile(loss='mse', optimizer=(lr=self.learning_rate))\n",
    "        \n",
    "       \n",
    "        #\n",
    "        # self.model = Sequential()\n",
    "        # self.model.add(Dense(16, input_shape=(observation_space,), activation=\"relu\"))\n",
    "        # self.model.add(Dense(16, activation=\"relu\"))\n",
    "        # self.model.add(Dense(self.action_space, activation=\"linear\"))\n",
    "        # self.model.compile(loss=\"mse\", optimizer=Adam(lr=0.001))\n",
    "        return model\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "    \n",
    "    #After some time interval update the target model to be same with model\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    #Get action from model using epsilon-greedy policy\n",
    "    def get_action(self, state):\n",
    "\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            ##############################################################\n",
    "            # try out the self-designed method\n",
    "            # First train:\n",
    "#             action_range = [x for x in range(self.action_size)]\n",
    "#             access = np.array([0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0])\n",
    "#             action = np.random.choice(action_range, p=access/sum(access))\n",
    "            # Second train:\n",
    "#             q_value = self.model.predict(state)\n",
    "#             ind =  np.argmax(q_value[0])\n",
    "#             action = random.choice([ind - 1, ind, ind + 1])\n",
    "#             if action < 0:\n",
    "#                 action = 0\n",
    "#             if action > self.action_size - 1:\n",
    "#                 action = self.action_size - 1\n",
    "            ###############################################################\n",
    "            action =  random.randrange(self.action_size)\n",
    "#             print(\"action:\", action)\n",
    "        else:\n",
    "            q_value = self.model.predict(state)\n",
    "            action =  np.argmax(q_value[0])\n",
    "            \n",
    "        # Annealing epsilon over time\n",
    "        if self.epsilon >= FINAL_EPSILON and len(self.memory) >= self.train_start:\n",
    "            self.epsilon -= self.epsilon_interval\n",
    "        return action\n",
    "    def get_action_test(self, state):\n",
    "        q_value = self.model.predict(state)\n",
    "        action =  np.argmax(q_value[0])\n",
    "        return action\n",
    "        \n",
    "###############################################################################\n",
    "###############################################################################\n",
    "    #Save sample <s,a,r,s'> to the replay memory\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done)) #Add sample to the end of the list\n",
    "\n",
    "    #Sample <s,a,r,s'> from replay memory\n",
    "    def train_model(self):\n",
    "        if len(self.memory) < self.train_start: #Do not train if not enough memory\n",
    "            return\n",
    "        batch_size = min(self.batch_size, len(self.memory)) #Train on at most as many samples as you have in memory\n",
    "        mini_batch = random.sample(self.memory, batch_size) #Uniformly sample the memory buffer\n",
    "        #Preallocate network and target network input matrices.\n",
    "        update_input = np.zeros((batch_size, self.state_size)) #batch_size by state_size two-dimensional array (not matrix!)\n",
    "        update_target = np.zeros((batch_size, self.state_size)) #Same as above, but used for the target network\n",
    "        action, reward, done = [], [], [] #Empty arrays that will grow dynamically\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            update_input[i] = mini_batch[i][0]#Allocate s(i) to the network input array from iteration i in the batch\n",
    "            action.append(mini_batch[i][1]) #Store a(i)\n",
    "            reward.append(mini_batch[i][2]) #Store r(i)\n",
    "            update_target[i] = mini_batch[i][3] #Allocate s'(i) for the target network array from iteration i in the batch\n",
    "            done.append(mini_batch[i][4])  #Store done(i)\n",
    "\n",
    "        target = self.model.predict(update_input) #Generate target values for training the inner loop network using the network model\n",
    "        target_val = self.target_model.predict(update_target) #Generate the target values for training the outer loop target network\n",
    "        #Q Learning: get maximum Q value at s' from target network\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "        #Insert your Q-learning code here\n",
    "        #Tip 1: Observe that the Q-values are stored in the variable target\n",
    "        #Tip 2: What is the Q-value of the action taken at the last state of the episode?\n",
    "        for i in range(self.batch_size): #For every batch\n",
    "            # target[i][action[i]] = random.randint(0,1)\n",
    "            ############################################################### edited by andy\n",
    "#             action2ind = {(-0.0001, 0):0,(0.0001, 0):1,(0 , -0.0001):2,(0, 0.0001):3}\n",
    "#             action2ind = {(-0.0001, 0):0, (-0.01, 0):1,(0.0001, 0):2, (0.01, 0):3,(0 , -0.0001):4, (0, -0.01):5,(0, 0.0001):6, (0, 0.01):7}\n",
    "            \n",
    "#             action_tuple = tuple(action[i])\n",
    "#             action_ind = action2ind[action_tuple]\n",
    "            action_ind = self.action_space.index(action[i])\n",
    "            if done[i]:\n",
    "                target[i][action_ind]= reward[i]\n",
    "            else:\n",
    "                target[i][action_ind] = reward[i] + self.discount_factor * (\n",
    "                    np.amax(target_val[i]))\n",
    "            #################################################################\n",
    "#             if done[i]:\n",
    "#                 target[i][action[i]]= reward[i]\n",
    "#             else:\n",
    "#                 target[i][action[i]] = reward[i] + self.discount_factor * (\n",
    "#                     np.amax(target_val[i]))\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "\n",
    "        #Train the inner loop network\n",
    "        self.model.fit(update_input, target, batch_size=self.batch_size,\n",
    "                       epochs=1, verbose=0)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def save_model(self, path_to_model, path_to_target):\n",
    "            self.model.save(path_to_model)\n",
    "            self.target_model.save(path_to_target)\n",
    "            return\n",
    "        \n",
    "    def restore_model(self, path_to_model, path_to_target):\n",
    "            self.model = load_model(path_to_model)\n",
    "            self.target_model = load_model(path_to_target)\n",
    "            return\n",
    "        \n",
    "    #Plots the score per episode as well as the maximum q value per episode, averaged over precollected states.\n",
    "    def plot_data(self, episodes, scores, max_q_mean, success_log):\n",
    "        pylab.figure(0)\n",
    "        pylab.plot(episodes, max_q_mean, 'b')\n",
    "        pylab.xlabel(\"Episodes\")\n",
    "        pylab.ylabel(\"Average Q Value\")\n",
    "        pylab.savefig(\"modelnpic/qvalues.png\")\n",
    "\n",
    "        pylab.figure(1)\n",
    "        pylab.plot(episodes, scores, 'b')\n",
    "        pylab.xlabel(\"Episodes\")\n",
    "        pylab.ylabel(\"Score\")\n",
    "        pylab.savefig(\"modelnpic/scores.png\")\n",
    "        \n",
    "        \n",
    "        pylab.figure(2)\n",
    "        pylab.plot(episodes, success_log, 'b')\n",
    "        pylab.xlabel(\"Episodes\")\n",
    "        pylab.ylabel(\"Successes\")\n",
    "        pylab.savefig(\"modelnpic/successes.png\")\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    env = gym.make('Reacher-v2') #Generate Reacher-v2 environment object from the gym library\n",
    "    #Get state and action sizes from the environment\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = len(env.action_space)\n",
    "#     action_size = env.action_space.n\n",
    "    #Create agent, see the DQNAgent __init__ method for details\n",
    "    agent = DQNAgent(state_size, env.action_space)\n",
    "    \n",
    "    #load the pre-trained model\n",
    "    if os.path.isdir('./modelnpic/'):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs('./modelnpic/')\n",
    "    path_to_model = 'modelnpic/model_adam.h5'\n",
    "    path_to_target = 'modelnpic/target_model_adam.h5'\n",
    "    if os.path.isfile(path_to_model) and os.path.isfile(path_to_target):\n",
    "        print(\"Loading the pre-trained model......\")\n",
    "        agent.restore_model(path_to_model, path_to_target)\n",
    "    else:\n",
    "        print(\"Pre-trained model doesn't exist.\")\n",
    "    \n",
    "\n",
    "    #Collect test states for plotting Q values using uniform random policy\n",
    "    test_states = np.zeros((agent.test_state_no, state_size))\n",
    "    max_q = np.zeros((EPISODES, agent.test_state_no))\n",
    "    max_q_mean = np.zeros((EPISODES,1))\n",
    "    done = True\n",
    "    for i in range(agent.test_state_no):\n",
    "        if done:\n",
    "            done = False\n",
    "            state = env.reset()\n",
    "            state = np.reshape(state, [1, state_size])\n",
    "            test_states[i] = state\n",
    "        else:\n",
    "            #############################\n",
    "#             action = random.randrange(action_size)\n",
    "\n",
    "            action_idx = random.randrange(action_size)\n",
    "            action = env.action_space[action_idx]\n",
    "            ###################################\n",
    "#             if done:\n",
    "#                 print(\"Before Done: \", done)\n",
    "            next_state, reward, done, info= env.step(action)\n",
    "#             if done:\n",
    "#                 print(\"Done: \", done)\n",
    "#                 print(\"Info: \", info)\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            test_states[i] = state\n",
    "            state = next_state\n",
    "\n",
    "    scores, episodes = [], [] #Create dynamically growing score and episode counters\n",
    "    success_log = []\n",
    "    success_count = 0\n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        state = env.reset() #Initialize/reset the environment\n",
    "        state = np.reshape(state, [1, state_size]) #Reshape state so that to a 1 by state_size two-dimensional array ie. [x_1,x_2] to [[x_1,x_2]]\n",
    "        #Compute Q values for plotting\n",
    "        tmp = agent.model.predict(test_states)  # tmp.shape = num of test states * num of actions\n",
    "        max_q[e][:] = np.max(tmp, axis=1)\n",
    "        max_q_mean[e] = np.mean(max_q[e][:])\n",
    "#         print(\"e: \", e)\n",
    "#         print(\"tmp: \", tmp.shape)\n",
    "#         print(\"test_states: \", test_states.shape)\n",
    "        \n",
    "        count = 0 \n",
    "        while not done:\n",
    "            \n",
    "            if agent.render:\n",
    "                env.render() #Show cartpole animation\n",
    "\n",
    "            #Get action for the current state and go one step in environment\n",
    "            ###################################\n",
    "#             action = agent.get_action(state)\n",
    "            action_idx = agent.get_action(state)\n",
    "            action = env.action_space[action_idx]\n",
    "            ###################################\n",
    "            next_state, reward, done, success= env.step(action)\n",
    "            \n",
    "            next_state = np.reshape(next_state, [1, state_size]) #Reshape next_state similarly to state\n",
    "\n",
    "            #Save sample <s, a, r, s'> to the replay memory\n",
    "            agent.append_sample(state, action, reward, next_state, done)\n",
    "            #Training step\n",
    "            agent.train_model()\n",
    "            score += reward #Store episodic reward\n",
    "            state = next_state #Propagate state\n",
    "\n",
    "            if done:\n",
    "                #At the end of very episode, update the target network\n",
    "                if e % agent.target_update_frequency == 0:\n",
    "                    agent.update_target_model()\n",
    "                #Plot the play time for every episode\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                if success:\n",
    "                    print(\"Success!\")\n",
    "                    success_count += 1\n",
    "                success_log.append(success_count)\n",
    "                \n",
    "                print(\"episode:\", e, \"  score:\", score,\" q_value:\", max_q_mean[e],\"  memory length:\",\n",
    "                      len(agent.memory))\n",
    "\n",
    "                # if the mean of scores of last 100 episodes is bigger than 195\n",
    "                # stop training\n",
    "                if agent.check_solve:\n",
    "                    last_hundred_q_mean = np.mean(max_q_mean[-min(100, len(max_q_mean)):])\n",
    "                    if abs(last_hundred_q_mean - max_q_mean[e]) / last_hundred_q_mean  <= 0.01:\n",
    "                        print(\"solved after\", e-100, \"episodes\")\n",
    "                        agent.save_model(path_to_model, path_to_target)\n",
    "                        print(\"Models are saved.\")\n",
    "                        agent.plot_data(episodes,scores,max_q_mean[:e+1], success_log)\n",
    "                        sys.exit()\n",
    "    agent.plot_data(episodes,scores,max_q_mean, success_log)\n",
    "    # Save the model\n",
    "    agent.save_model(path_to_model, path_to_target)\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 16)                192       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 16)                192       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Loading the pre-trained model......\n",
      "Episode:  1\n",
      "Creating window glfw\n",
      "Total steps:  100\n",
      "Episode:  2\n",
      "Total steps:  100\n",
      "Episode:  3\n",
      "Total steps:  100\n",
      "Episode:  4\n",
      "Total steps:  100\n",
      "Episode:  5\n",
      "Total steps:  100\n",
      "Episode:  6\n",
      "Total steps:  100\n",
      "Episode:  7\n",
      "Total steps:  100\n",
      "Episode:  8\n",
      "Total steps:  100\n",
      "Episode:  9\n",
      "Total steps:  100\n",
      "Episode:  10\n",
      "Total steps:  100\n",
      "Episode:  11\n",
      "Total steps:  100\n",
      "Episode:  12\n",
      "Total steps:  100\n",
      "Episode:  13\n",
      "Total steps:  100\n",
      "Episode:  14\n",
      "Total steps:  100\n",
      "Episode:  15\n",
      "Total steps:  100\n",
      "Episode:  16\n",
      "Total steps:  100\n",
      "Episode:  17\n",
      "Total steps:  100\n",
      "Episode:  18\n",
      "Total steps:  100\n",
      "Episode:  19\n",
      "Total steps:  100\n",
      "Episode:  20\n",
      "Total steps:  100\n",
      "Episode:  21\n",
      "Total steps:  100\n",
      "Episode:  22\n",
      "Total steps:  100\n",
      "Episode:  23\n",
      "Total steps:  100\n",
      "Episode:  24\n",
      "Total steps:  100\n",
      "Episode:  25\n",
      "Total steps:  100\n",
      "Episode:  26\n",
      "Total steps:  100\n",
      "Episode:  27\n",
      "Total steps:  100\n",
      "Episode:  28\n",
      "Total steps:  100\n",
      "Episode:  29\n",
      "Total steps:  100\n",
      "Episode:  30\n",
      "Total steps:  100\n",
      "Episode:  31\n",
      "Total steps:  100\n",
      "Episode:  32\n",
      "Total steps:  100\n",
      "Episode:  33\n",
      "Total steps:  100\n",
      "Episode:  34\n",
      "Total steps:  100\n",
      "Episode:  35\n",
      "Total steps:  100\n",
      "Episode:  36\n",
      "Total steps:  100\n",
      "Episode:  37\n",
      "Total steps:  100\n",
      "Episode:  38\n",
      "Total steps:  100\n",
      "Episode:  39\n",
      "Total steps:  100\n",
      "Episode:  40\n",
      "Total steps:  100\n",
      "Episode:  41\n",
      "Total steps:  100\n",
      "Episode:  42\n",
      "Total steps:  100\n",
      "Episode:  43\n",
      "Total steps:  100\n",
      "Episode:  44\n",
      "Total steps:  100\n",
      "Episode:  45\n",
      "Total steps:  100\n",
      "Episode:  46\n",
      "Total steps:  100\n",
      "Episode:  47\n",
      "Total steps:  100\n",
      "Episode:  48\n",
      "Total steps:  100\n",
      "Episode:  49\n",
      "Total steps:  100\n",
      "Episode:  50\n",
      "Total steps:  100\n",
      "Rewards:  [-26.519040166410292, -17.5582753411983, -407.05714353147516, -9.30165551737184, -412.12379128610615, -413.27335586714315, -416.56335386342505, -417.32855463971015, -411.1603762640842, -37.49736606612743, -19.772998966307654, -24.488081615545873, -27.24217569163982, -6.710323652718476, -23.378179643020044, -8.543399331237024, -27.875461305767775, -11.451519122383933, -415.38754530050204, -414.8755432804826, -12.724427933520223, -409.1623641055916, -22.77878019111606, -24.001534361243486, -417.82075563831165, -24.401565881287755, -11.290768480609316, -407.7064391090046, -20.55942454747056, -406.4407016662483, -7.8815392280483705, -33.87763589030059, -9.32252247913665, -410.69721137498516, -9.241381681749504, -9.529348115885993, -413.0352138210454, -416.40885996886317, -14.9294548065262, -417.5768502451131, -29.830471695583334, -33.15677962883748, -415.16954527788465, -417.50223417510966, -29.380665972213205, -18.911822117170622, -27.66481216369558, -28.110797137424886, -12.700106406733235, -17.50258076560864]\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import gym\n",
    "from gym import wrappers\n",
    "EPISODES = 50\n",
    "env = gym.make(\"Reacher-v2\")\n",
    "# env = wrappers.Monitor(env, './videos/' + str(time()) + '/')\n",
    "#Create agent, see the DQNAgent __init__ method for details\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = len(env.action_space)\n",
    "agent = DQNAgent(state_size, env.action_space)\n",
    "\n",
    "# load the pre-trained model\n",
    "path_to_model = 'modelnpic/model_adam.h5'\n",
    "path_to_target = 'modelnpic/target_model_adam.h5'\n",
    "if os.path.isfile(path_to_model) and os.path.isfile(path_to_target):\n",
    "    print(\"Loading the pre-trained model......\")\n",
    "    agent.restore_model(path_to_model, path_to_target)\n",
    "else:\n",
    "    print(\"Pre-trained model doesn't exist.\")\n",
    "    \n",
    "\n",
    "\n",
    "test_rewards = []\n",
    "test_start = time()\n",
    "test_steps = 0\n",
    "for e in range(1, 1 + EPISODES):\n",
    "    print(\"Episode: \", e)\n",
    "    steps = 0\n",
    "    state = env.reset()\n",
    "    state = np.expand_dims(state, axis=0)#Reshape state so that to a 1 by state_size two-dimensional array ie. [x_1,x_2] to [[x_1,x_2]]\n",
    "    iter_rewards = 0.0\n",
    "    done = False\n",
    "    while not done:\n",
    "        env.render()\n",
    "        steps += 1\n",
    "        test_steps += 1\n",
    "        action = agent.get_action_test(state)  # always choose the optimal action\n",
    "        state, reward, done, touch = env.step(action)\n",
    "        state = np.expand_dims(state, axis=0)\n",
    "        if touch:\n",
    "            print(\"Successfully touch the target!!!!\")\n",
    "            print(\"Done: \", done)\n",
    "#         state = np.expand_dims(state, axis=0)#Reshape state so that to a 1 by state_size two-dimensional array ie. [x_1,x_2] to [[x_1,x_2]]\n",
    "        iter_rewards += reward\n",
    "    test_rewards.append(iter_rewards)\n",
    "    print(\"Total steps: \", steps)\n",
    "print(\"Rewards: \", test_rewards)\n",
    "#print_stats('Test', test_rewards, args.n_test_iter,\n",
    "            #time() - test_start, test_steps, 0, agent)\n",
    "\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
